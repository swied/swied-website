[
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/intro-to-pyspark/Intro-to-Pyspark.html",
    "href": "posts/intro-to-pyspark/Intro-to-Pyspark.html",
    "title": "Intro to Pyspark",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\n\n\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\n\n\nimport pyspark.sql.types as T\nimport pyspark.sql.functions as F\n\n\n\n\npdf = pd.DataFrame({'x':[1,2,3], 'y':[5,6,7]})\npdf.to_csv('test.csv')\npdf.head()\n\n\n\n\n\n  \n    \n      \n      x\n      y\n    \n  \n  \n    \n      0\n      1\n      5\n    \n    \n      1\n      2\n      6\n    \n    \n      2\n      3\n      7\n    \n  \n\n\n\n\n\n\n\n\nspark.sql(\"select 1+1\").show()\n\n+-------+\n|(1 + 1)|\n+-------+\n|      2|\n+-------+\n\n\n\n\n\n\n1+1\n\n2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Scott's Data Science Blog",
    "section": "",
    "text": "Hi,\nThanks for visiting my blog! I decided to start writing these articles in order to share with others how I do Data Science. It is also meant to demonstrate my skill set to prospective employers. I hope you enjoy it.\nThanks,\nScott\n\n\nArticles\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGet Financial Data by Stock Ticker From the data.sec.gov API\n\n\n\nPandas\nAPI's\nMatplotlib\nFinance\nPython\n\n\n\nA notebook, with code, showing how to pull data from sec.gov web API’s\n\n\n\nNov 6, 2022\nScott Wied\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog About this blogAbout this blogAbout this blogAbout this blogAbout this blogAbout this blogAbout this blogAbout this blogAbout this blogAbout this blogAbout this blogAbout this blogAbout this blogAbout this blogAbout this blogAbout this blogAbout this blogAbout this blogAbout this blogAbout this blogAbout this blog"
  },
  {
    "objectID": "posts/tmp/Untitled.html",
    "href": "posts/tmp/Untitled.html",
    "title": "Post Title",
    "section": "",
    "text": "Intro…..\n\n\nBefore we start this discussion I think it’s important to show how easy it is to install Pyspark. I recommend using Anaconda to do the PySpark installation. It only involves a few simple steps – assuming you already have Anaconda working. I won’t go into that here. I noticed that Pandas was one of the dependencies for the PySpark installation, so we kill two birds with one stone.\nOpen a Terminal and execute the following commands one at a time.\n\nTerminal\n\n\n# Step 1: Activate your existing conda env\nconda activate pyspark_env\n\n# Step 2: Install Open JDK\nconda install openjdk\n\n# Step 3: Install Pyspark\nconda install pyspark\n\n# Step 4: Install findspark in order to run Pyspark in a Jupyter notebook\nconda install -c conda-forge findspark\n\n\n\n\n\n\n\nimport pandas as pd\nimport pyspark.sql.types as T\nimport pyspark.sql.functions as F\nimport pyspark.sql.window as W\nfrom pyspark.sql import SparkSession\n\n\n# Create a new spark session\nspark = SparkSession.builder.getOrCreate()\n# spark = SparkSession.builder.appName(\"intro\").getOrCreate()\n\n\n# Check to see if our spark session is working\nspark.sql(\"select 'hello world' as greeting\").show()\n\n+-----------+\n|   greeting|\n+-----------+\n|hello world|\n+-----------+\n\n\n\n\n\n\n\n# Field values\nplayer_ids  = [1,2,3,4,5,6,7,8,9,10]\nfirst_names = ['juan','Manny','Yu','He-Seong','JURICKSON','jake','Brandon','JOSH','Trent','Austin']\nlast_names  = ['soto', 'Machado', 'Darvish', 'Kim','PROFAR','cronenworth','Drury','BELL','Grisham','Nola']\npositions   = ['RF','3B','P','SS','LF','2B','1B','DH','CF','C']\nbatting     = ['L','R',None,'R','S','L','R','S','L','R']\nat_bats     = [524,578,None,517,575,587,518,552,451,347]\nobp         = [0.401,0.366,None,0.325,0.331,0.332,0.320,0.362,0.284,0.321]\nteams       = ['Padres' for x in range(10)]\n\n\n\n\nPandasPyspark\n\n\n\n# Create a new Pandas dataframe from the field lists from above\ndf = pd.DataFrame({'player_id':player_ids,\n                   'team':teams,\n                   'first_name':first_names,\n                   'last_name':last_names,\n                   'position':positions,\n                   'batting_stance':batting,\n                   'at_bats':at_bats,\n                   'obp':obp})\n\n\n\n\n# If you are going to create a PySpark dataframe from inline code, then \n# it is actually easiest to just create the dataframe in Pandas, and \n# then convert it to Pyspark.  \ndf = spark.createDataFrame(\n    pd.DataFrame({'player_id':player_ids,\n                   'team':teams,\n                   'first_name':first_names,\n                   'last_name':last_names,\n                   'position':positions,\n                   'batting_stance':batting,\n                   'at_bats':at_bats,\n                   'obp':obp}))\n\n\n\n\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      player_id\n      team\n      first_name\n      last_name\n      position\n      batting_stance\n      at_bats\n      obp\n    \n  \n  \n    \n      0\n      1\n      Padres\n      juan\n      soto\n      RF\n      L\n      524.0\n      0.401\n    \n    \n      1\n      2\n      Padres\n      Manny\n      Machado\n      3B\n      R\n      578.0\n      0.366\n    \n    \n      2\n      3\n      Padres\n      Yu\n      Darvish\n      P\n      None\n      NaN\n      NaN\n    \n    \n      3\n      4\n      Padres\n      He-Seong\n      Kim\n      SS\n      R\n      517.0\n      0.325\n    \n    \n      4\n      5\n      Padres\n      JURICKSON\n      PROFAR\n      LF\n      S\n      575.0\n      0.331\n    \n  \n\n\n\n\n\n\n\n\nTask Description: (1) Notice that the capitalization is not consistent on the first and last names of the players. Fix this so that each name has only the first letter capitolized. (2) Create a new column showing the initials of each player.\n\n\nI think it makes it more readable to chain together Pandas function calls by putting them inside of a set of parantheses. The assign function is useful for doing this sort of chaining.\n\nPandasPyspark\n\n\n\ndf_task_1 = (\n    df\n    # (1) Capitalize the first letter of both the first and last names\n    .assign(first_name = lambda x: x.first_name.str.title())\n    .assign(last_name  = lambda x: x.last_name.str.title())\n    # (2) Creat a new field showing the initals of each player\n    .assign(initials    = lambda x: x.first_name.str[0:1] + '.' + x.last_name.str[0:1] + '.')\n)\n\n\n\n\ndf_task_1 = (\n    df\n    # (1) Capitalize the first letter of both the first and last names\n    .withColumn('first_name', F.initcap(F.col('first_name')))\n    .withColumn('last_name',  F.initcap(F.col('last_name')))\n    # (2) Creat a new field showing the initals of each player\n    .withColumn('initials', F.concat(F.substring('first_name',0,1), F.lit('.'), F.substring('last_name', 0, 1), F.lit('.')))\n)\n\n\n\n\n\ndf_task_1.head()\n\n\n\n\n\n  \n    \n      \n      player_id\n      team\n      first_name\n      last_name\n      position\n      batting_stance\n      at_bats\n      obp\n      initials\n    \n  \n  \n    \n      0\n      1\n      Padres\n      Juan\n      Soto\n      RF\n      L\n      524.0\n      0.401\n      J.S.\n    \n    \n      1\n      2\n      Padres\n      Manny\n      Machado\n      3B\n      R\n      578.0\n      0.366\n      M.M.\n    \n    \n      2\n      3\n      Padres\n      Yu\n      Darvish\n      P\n      None\n      NaN\n      NaN\n      Y.D.\n    \n    \n      3\n      4\n      Padres\n      He-Seong\n      Kim\n      SS\n      R\n      517.0\n      0.325\n      H.K.\n    \n    \n      4\n      5\n      Padres\n      Jurickson\n      Profar\n      LF\n      S\n      575.0\n      0.331\n      J.P.\n    \n  \n\n\n\n\n:::: {.columns} ::: {.column width=“50%”} ### Pyspark\n\n\n\n\n\nThis is the most common way I that I have seen people solving this task after searching the internet. You need to look at it for a bit to understand what is going on. I’m not a big fan of the apply function. I think that list comprehensions are a more pythonic way of doing the same task.\n\ndf_pandas['full_name'] = df_pandas[[\"first_name\", \"last_name\"]].apply(\" \".join, axis=1)\ndf_pandas.head(3)\n\n\n\n\n\n  \n    \n      \n      player_id\n      team\n      first_name\n      last_name\n      position\n      batting_stance\n      at_bats\n      obp\n      full_name\n    \n  \n  \n    \n      0\n      1\n      Padres\n      juan\n      soto\n      RF\n      L\n      524.0\n      0.401\n      juan soto\n    \n    \n      1\n      2\n      Padres\n      Manny\n      Machado\n      3B\n      R\n      578.0\n      0.366\n      Manny Machado\n    \n    \n      2\n      3\n      Padres\n      Yu\n      Darvish\n      P\n      None\n      NaN\n      NaN\n      Yu Darvish\n    \n  \n\n\n\n\n\n\n\nHere is a solution that uses the same technique as above, but with a list comprehension instead of an apply function. It may be a bit more “pythonic”, but it is still not pretty.\n\ndf_pandas['full_name'] = [f\"{x[0]} {x[1]}\" for x in zip(df_pandas[\"first_name\"], df_pandas[\"last_name\"])]\ndf_pandas.head(3)\n\n\n\n\n\n  \n    \n      \n      player_id\n      team\n      first_name\n      last_name\n      position\n      batting_stance\n      at_bats\n      obp\n      full_name\n    \n  \n  \n    \n      0\n      1\n      Padres\n      juan\n      soto\n      RF\n      L\n      524.0\n      0.401\n      juan soto\n    \n    \n      1\n      2\n      Padres\n      Manny\n      Machado\n      3B\n      R\n      578.0\n      0.366\n      Manny Machado\n    \n    \n      2\n      3\n      Padres\n      Yu\n      Darvish\n      P\n      None\n      NaN\n      NaN\n      Yu Darvish\n    \n  \n\n\n\n\n\n\n\nThis is my favorite Pandas solution. I like being able to change dataframe operations in series. I can use the assign function to accomplish this task. Unfortunately, like the previous 2 solutions, it is also bit ugly. It involves using a lambda function, a list comprehension, and the zip iterator function. It’s kind of crazy, but it all fits onto a single line. Once you memorize the pattern you can do this sort of assignment operation one line after another.\n\n(\n    df_pandas\n    .assign(full_name = lambda x: [f\"{y[0]} {y[1]}\" for y in zip(x.first_name, x.last_name)])\n    .head(3)\n)\n\n\n\n\n\n  \n    \n      \n      player_id\n      team\n      first_name\n      last_name\n      position\n      batting_stance\n      at_bats\n      obp\n      full_name\n    \n  \n  \n    \n      0\n      1\n      Padres\n      juan\n      soto\n      RF\n      L\n      524.0\n      0.401\n      juan soto\n    \n    \n      1\n      2\n      Padres\n      Manny\n      Machado\n      3B\n      R\n      578.0\n      0.366\n      Manny Machado\n    \n    \n      2\n      3\n      Padres\n      Yu\n      Darvish\n      P\n      None\n      NaN\n      NaN\n      Yu Darvish\n    \n  \n\n\n\n\n\n\n\nI have saved the best solution for last. As you saw above, there is no straight forward way to accomplish this task using Pandas. This Pyspark solution is just as wordy. However, in my opinion, it way more straight forward. It is just a few funtion calls.\n\n(\n    df_pyspark\n    .withColumn('full_name', F.concat(F.col('first_name'), F.lit(' '), F.col('last_name')))\n    .toPandas()\n    .head(3)\n)\n\n\n\n\n\n  \n    \n      \n      player_id\n      team\n      first_name\n      last_name\n      position\n      batting_stance\n      at_bats\n      obp\n      full_name\n    \n  \n  \n    \n      0\n      1\n      Padres\n      juan\n      soto\n      RF\n      L\n      524.0\n      0.401\n      juan soto\n    \n    \n      1\n      2\n      Padres\n      Manny\n      Machado\n      3B\n      R\n      578.0\n      0.366\n      Manny Machado\n    \n    \n      2\n      3\n      Padres\n      Yu\n      Darvish\n      P\n      None\n      NaN\n      NaN\n      Yu Darvish\n    \n  \n\n\n\n\n\n\n\n\n\n\n\n(\n    df_pandas\n    .head()\n)\n\n\n\n\n\n  \n    \n      \n      player_id\n      team\n      first_name\n      last_name\n      position\n      batting_stance\n      at_bats\n      obp\n      full_name\n    \n  \n  \n    \n      0\n      1\n      Padres\n      juan\n      soto\n      RF\n      L\n      524.0\n      0.401\n      juan soto\n    \n    \n      1\n      2\n      Padres\n      Manny\n      Machado\n      3B\n      R\n      578.0\n      0.366\n      Manny Machado\n    \n    \n      2\n      3\n      Padres\n      Yu\n      Darvish\n      P\n      None\n      NaN\n      NaN\n      Yu Darvish\n    \n    \n      3\n      4\n      Padres\n      He-Seong\n      Kim\n      SS\n      R\n      517.0\n      0.325\n      He-Seong Kim\n    \n    \n      4\n      5\n      Padres\n      JURICKSON\n      PROFAR\n      LF\n      S\n      575.0\n      0.331\n      JURICKSON PROFAR\n    \n  \n\n\n\n\n\n\n\n\n(\n    df_pyspark\n    .filter(F.col('position')!='P')\n    .withColumn('total_at_bats', F.sum('at_bats').over(W.Window.partitionBy('team')))\n    .withColumn('pct_total_at_bats', F.col('at_bats')/F.col('total_at_bats'))\n    .toPandas()\n    .head(3)\n)\n\n\n\n\n\n  \n    \n      \n      player_id\n      team\n      first_name\n      last_name\n      position\n      batting_stance\n      at_bats\n      obp\n      total_at_bats\n      pct_total_at_bats\n    \n  \n  \n    \n      0\n      1\n      Padres\n      juan\n      soto\n      RF\n      L\n      524.0\n      0.401\n      4649.0\n      0.112712\n    \n    \n      1\n      2\n      Padres\n      Manny\n      Machado\n      3B\n      R\n      578.0\n      0.366\n      4649.0\n      0.124328\n    \n    \n      2\n      4\n      Padres\n      He-Seong\n      Kim\n      SS\n      R\n      517.0\n      0.325\n      4649.0\n      0.111207"
  },
  {
    "objectID": "posts/tmp/test.html",
    "href": "posts/tmp/test.html",
    "title": "Post Title",
    "section": "",
    "text": "tab 1tab 2tab 3\n\n\nhello world\n\n\n\n\n\n\n\n\n\n::::\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/stock_ticker_data/stock_ticker_data.html",
    "href": "posts/stock_ticker_data/stock_ticker_data.html",
    "title": "Get Financial Data by Stock Ticker From the data.sec.gov API",
    "section": "",
    "text": "import urllib\nimport requests\nimport json\nfrom pprint import pprint\nimport pandas as pd\nimport numpy as np\nfrom collections import namedtuple\nimport re\nimport matplotlib.pyplot as plt\n\n\n\n\n\nticker = 'AAPL'\nemail_address = 'your-email@example.com'  # Enter your email address here.  It needs to be included in the URL of the API call.\n\n\n\n\n\n\n\n# Run the API request   \nrequest_info = requests.get('https://www.sec.gov/files/company_tickers_exchange.json')\n\n# Print the returned status code (200 is good, 404 is bad) and other content info.\nprint(\"Request status code:\", request_info.status_code)\nprint(\"Content Type:\", request_info.headers['Content-Type'])\nprint(\"Content Length:\", request_info.headers['Content-Length'], 'bytes')\n\nRequest status code: 200\nContent Type: application/json\nContent Length: 214545 bytes\n\n\n\n# Put the requested content into a Python dict object using the `.json()` method\nrequest_data = request_info.json()\n\n\n\n\n\n# We know that request_data is a dictionary, so let's list all of its keys. \nprint(\"request_data:\", request_data.keys())\n\nrequest_data: dict_keys(['fields', 'data'])\n\n\n\nrequest_data['fields']\n\n['cik', 'name', 'ticker', 'exchange']\n\n\n\nrequest_data['data'][0:10]\n\n[[320193, 'Apple Inc.', 'AAPL', 'Nasdaq'],\n [789019, 'MICROSOFT CORP', 'MSFT', 'Nasdaq'],\n [1018724, 'AMAZON COM INC', 'AMZN', 'Nasdaq'],\n [1067983, 'BERKSHIRE HATHAWAY INC', 'BRK-B', 'NYSE'],\n [731766, 'UNITEDHEALTH GROUP INC', 'UNH', 'NYSE'],\n [34088, 'EXXON MOBIL CORP', 'XOM', 'NYSE'],\n [200406, 'JOHNSON & JOHNSON', 'JNJ', 'NYSE'],\n [104169, 'Walmart Inc.', 'WMT', 'NYSE'],\n [19617, 'JPMORGAN CHASE & CO', 'JPM', 'NYSE'],\n [93410, 'CHEVRON CORP', 'CVX', 'NYSE']]\n\n\n\n\n\n\n# Create a new dataframe\ndf_tickers = (\n    pd.DataFrame(data=request_data['data'], \n                 columns=request_data['fields'])\n    .set_index('ticker')\n)\n\n# Display the top few rows\ndf_tickers.head()\n\n\n\n\n\n  \n    \n      \n      cik\n      name\n      exchange\n    \n    \n      ticker\n      \n      \n      \n    \n  \n  \n    \n      AAPL\n      320193\n      Apple Inc.\n      Nasdaq\n    \n    \n      MSFT\n      789019\n      MICROSOFT CORP\n      Nasdaq\n    \n    \n      AMZN\n      1018724\n      AMAZON COM INC\n      Nasdaq\n    \n    \n      BRK-B\n      1067983\n      BERKSHIRE HATHAWAY INC\n      NYSE\n    \n    \n      UNH\n      731766\n      UNITEDHEALTH GROUP INC\n      NYSE\n    \n  \n\n\n\n\n\n# Slice the dataframe to show only the row where ticker=='AAPL'\ndf_tickers.query(f\"ticker=='{ticker}'\")\n\n\n\n\n\n  \n    \n      \n      cik\n      name\n      exchange\n    \n    \n      ticker\n      \n      \n      \n    \n  \n  \n    \n      AAPL\n      320193\n      Apple Inc.\n      Nasdaq\n    \n  \n\n\n\n\n\n\n\nThis is necessary because in the next section we will need to add a formatted CID to the API call.\n\ndef get_cik_string(ticker_data, ticker_symbol):\n    ticker_symbol = ticker_symbol.upper()\n    data_slice = ticker_data.loc[[ticker_symbol],['cik']]\n    cik_value = data_slice.values[0][0]\n    cik_string = 'CIK' + str(cik_value).rjust(10, '0')\n    return cik_string\n\n\n# Example for our ticker\nprint(\"ticker:\", ticker)\nprint(\"CIK:\",    get_cik_string(df_tickers, ticker))\n\nticker: AAPL\nCIK: CIK0000320193\n\n\n\n\n\n\n\n# Build up the request URL\ncik = get_cik_string(df_tickers, ticker)\ntag = 'Assets'\nurl = f\"https://data.sec.gov/api/xbrl/companyconcept/{cik}/us-gaap/{tag}.json\"\n\nprint(\"URL:\", url)\n\n# Run the API request   \nrequest_tag_data = requests.get(url, headers={'User-Agent': email_address})\n\n# Print the returned status code (200 is good, 404 is bad), and other content info.\nprint(\"Request status code:\", request_tag_data.status_code)\nprint(\"Content Type:\", request_tag_data.headers['Content-Type'])\nprint(\"Content Length:\", request_tag_data.headers['Content-Length'], 'bytes')\n\nURL: https://data.sec.gov/api/xbrl/companyconcept/CIK0000320193/us-gaap/Assets.json\n\n\nRequest status code: 200\nContent Type: application/json\nContent Length: 2052 bytes\n\n\n\ntag_data = request_tag_data.json()\n\n\npprint(tag_data, depth=2)\n\n{'cik': 320193,\n 'description': 'Sum of the carrying amounts as of the balance sheet date of '\n                'all assets that are recognized. Assets are probable future '\n                'economic benefits obtained or controlled by an entity as a '\n                'result of past transactions or events.',\n 'entityName': 'Apple Inc.',\n 'label': 'Assets',\n 'tag': 'Assets',\n 'taxonomy': 'us-gaap',\n 'units': {'USD': [...]}}\n\n\n\ndf_tag_data = pd.DataFrame.from_dict(tag_data['units']['USD'])\n\n\ndf_tag_data\n\n\n\n\n\n  \n    \n      \n      end\n      val\n      accn\n      fy\n      fp\n      form\n      filed\n      frame\n    \n  \n  \n    \n      0\n      2008-09-27\n      39572000000\n      0001193125-09-153165\n      2009\n      Q3\n      10-Q\n      2009-07-22\n      NaN\n    \n    \n      1\n      2008-09-27\n      39572000000\n      0001193125-09-214859\n      2009\n      FY\n      10-K\n      2009-10-27\n      NaN\n    \n    \n      2\n      2008-09-27\n      36171000000\n      0001193125-10-012091\n      2009\n      FY\n      10-K/A\n      2010-01-25\n      NaN\n    \n    \n      3\n      2008-09-27\n      36171000000\n      0001193125-10-238044\n      2010\n      FY\n      10-K\n      2010-10-27\n      CY2008Q3I\n    \n    \n      4\n      2009-06-27\n      48140000000\n      0001193125-09-153165\n      2009\n      Q3\n      10-Q\n      2009-07-22\n      CY2009Q2I\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      111\n      2021-09-25\n      351002000000\n      0000320193-22-000108\n      2022\n      FY\n      10-K\n      2022-10-28\n      CY2021Q3I\n    \n    \n      112\n      2021-12-25\n      381191000000\n      0000320193-22-000007\n      2022\n      Q1\n      10-Q\n      2022-01-28\n      CY2021Q4I\n    \n    \n      113\n      2022-03-26\n      350662000000\n      0000320193-22-000059\n      2022\n      Q2\n      10-Q\n      2022-04-29\n      CY2022Q1I\n    \n    \n      114\n      2022-06-25\n      336309000000\n      0000320193-22-000070\n      2022\n      Q3\n      10-Q\n      2022-07-29\n      CY2022Q2I\n    \n    \n      115\n      2022-09-24\n      352755000000\n      0000320193-22-000108\n      2022\n      FY\n      10-K\n      2022-10-28\n      CY2022Q3I\n    \n  \n\n116 rows × 8 columns\n\n\n\n\n# Filter rows to only those with current year (CY) labels\nstarts_with_cy = lambda x: bool(isinstance(re.search(r'^CY', x), re.Match))\nx_axis_name = 'End Date'\ny_axis_name = f'{tag} (USD in Billions)'\n\ndf_plot_data = (\n    df_tag_data\n    .query(\"form=='10-Q'\")\n    .assign(yr_mon      = lambda x: [f\"{y[0]}-{y[1]}\" for y in zip(x.fy, x.fp)] )\n    .assign(filter_flag = lambda x: [starts_with_cy(str(y)) for y in x.frame])\n    .query(\"filter_flag==True\")\n    .filter(['end', 'val'])\n    .assign(val = lambda x: x.val/1000000000)\n    .rename(columns={'end':x_axis_name, 'val':y_axis_name})\n    .sort_values(by=x_axis_name)\n)\n\ndf_plot_data.tail(10)\n\n\n\n\n\n  \n    \n      \n      End Date\n      Assets (USD in Billions)\n    \n  \n  \n    \n      90\n      2019-06-29\n      322.239\n    \n    \n      96\n      2019-12-28\n      340.618\n    \n    \n      97\n      2020-03-28\n      320.400\n    \n    \n      98\n      2020-06-27\n      317.344\n    \n    \n      104\n      2020-12-26\n      354.054\n    \n    \n      105\n      2021-03-27\n      337.158\n    \n    \n      106\n      2021-06-26\n      329.840\n    \n    \n      112\n      2021-12-25\n      381.191\n    \n    \n      113\n      2022-03-26\n      350.662\n    \n    \n      114\n      2022-06-25\n      336.309\n    \n  \n\n\n\n\n\ndf_plot_data.plot(kind = 'bar', x = x_axis_name, y = y_axis_name, figsize=(12, 5), title = f\"{ticker} {tag}\")\nplt.show()"
  },
  {
    "objectID": "posts/stock_ticker_data/stock_ticker_data.html#define-the-ticker-we-wish-to-analyze",
    "href": "posts/stock_ticker_data/stock_ticker_data.html#define-the-ticker-we-wish-to-analyze",
    "title": "Scott's Data Science Blog",
    "section": "Define the ticker we wish to analyze",
    "text": "Define the ticker we wish to analyze\n\nticker = 'AAPL'\nemail_address = 'your-email@example.com'   # Needed for the data.sec.gove api call"
  },
  {
    "objectID": "posts/stock_ticker_data/stock_ticker_data.html#find-the-cik-number-for-the-chosen-stock-ticker",
    "href": "posts/stock_ticker_data/stock_ticker_data.html#find-the-cik-number-for-the-chosen-stock-ticker",
    "title": "Get Stock Ticker Data from the data.sec.gov API",
    "section": "3 Find the CIK number for the chosen stock ticker",
    "text": "3 Find the CIK number for the chosen stock ticker\n\n3.1 Request ticker exchange data from the sec.gov API\n\n# Run the API request   \nrequest_info = requests.get('https://www.sec.gov/files/company_tickers_exchange.json')\n\n# Print the returned status code (200 is good, 404 is bad) and other content info.\nprint(\"Request status code:\", request_info.status_code)\nprint(\"Content Type:\", request_info.headers['Content-Type'])\nprint(\"Content Length:\", request_info.headers['Content-Length'], 'bytes')\n\nRequest status code: 200\nContent Type: application/json\nContent Length: 214545 bytes\n\n\n\n# Put the requested content into a Python dict object using the `.json()` method\nrequest_data = request_info.json()\n\n\n\n3.2 Explore the data that was returned\n\n# We know that request_data is a dictionary, so let's list all of its keys. \nprint(\"request_data:\", request_data.keys())\n\nrequest_data: dict_keys(['fields', 'data'])\n\n\n\nrequest_data['fields']\n\n['cik', 'name', 'ticker', 'exchange']\n\n\n\nrequest_data['data'][0:10]\n\n[[320193, 'Apple Inc.', 'AAPL', 'Nasdaq'],\n [789019, 'MICROSOFT CORP', 'MSFT', 'Nasdaq'],\n [1018724, 'AMAZON COM INC', 'AMZN', 'Nasdaq'],\n [1067983, 'BERKSHIRE HATHAWAY INC', 'BRK-B', 'NYSE'],\n [731766, 'UNITEDHEALTH GROUP INC', 'UNH', 'NYSE'],\n [34088, 'EXXON MOBIL CORP', 'XOM', 'NYSE'],\n [200406, 'JOHNSON & JOHNSON', 'JNJ', 'NYSE'],\n [104169, 'Walmart Inc.', 'WMT', 'NYSE'],\n [19617, 'JPMORGAN CHASE & CO', 'JPM', 'NYSE'],\n [93410, 'CHEVRON CORP', 'CVX', 'NYSE']]\n\n\n\n\n3.3 Create a Pandas dataframe from the API content\n\n# Create a new dataframe\ndf_tickers = (\n    pd.DataFrame(data=request_data['data'], \n                 columns=request_data['fields'])\n    .set_index('ticker')\n)\n\n# Display the top few rows\ndf_tickers.head()\n\n\n\n\n\n  \n    \n      \n      cik\n      name\n      exchange\n    \n    \n      ticker\n      \n      \n      \n    \n  \n  \n    \n      AAPL\n      320193\n      Apple Inc.\n      Nasdaq\n    \n    \n      MSFT\n      789019\n      MICROSOFT CORP\n      Nasdaq\n    \n    \n      AMZN\n      1018724\n      AMAZON COM INC\n      Nasdaq\n    \n    \n      BRK-B\n      1067983\n      BERKSHIRE HATHAWAY INC\n      NYSE\n    \n    \n      UNH\n      731766\n      UNITEDHEALTH GROUP INC\n      NYSE\n    \n  \n\n\n\n\n\n# Slice the dataframe to show only the row where ticker=='AAPL'\ndf_tickers.query(f\"ticker=='{ticker}'\")\n\n\n\n\n\n  \n    \n      \n      cik\n      name\n      exchange\n    \n    \n      ticker\n      \n      \n      \n    \n  \n  \n    \n      AAPL\n      320193\n      Apple Inc.\n      Nasdaq\n    \n  \n\n\n\n\n\n\n3.4 Create a function to pull data for a single ticker and format the CIK as a string\nThis is necessary because in the next section we will need to add a formatted CID to the API call.\n\ndef get_cik_string(ticker_data, ticker_symbol):\n    ticker_symbol = ticker_symbol.upper()\n    data_slice = ticker_data.loc[[ticker_symbol],['cik']]\n    cik_value = data_slice.values[0][0]\n    cik_string = 'CIK' + str(cik_value).rjust(10, '0')\n    return cik_string\n\n\n# Example for our ticker\nprint(\"ticker:\", ticker)\nprint(\"CIK:\",    get_cik_string(df_tickers, ticker))\n\nticker: AAPL\nCIK: CIK0000320193"
  },
  {
    "objectID": "posts/stock_ticker_data/stock_ticker_data.html#get-financial-data-from-data.sec.gov-api-for-a-specific-xbrl-line-item-tag",
    "href": "posts/stock_ticker_data/stock_ticker_data.html#get-financial-data-from-data.sec.gov-api-for-a-specific-xbrl-line-item-tag",
    "title": "Get Stock Ticker Data from the data.sec.gov API",
    "section": "4 Get financial data from data.sec.gov api for a specific XBRL line item tag",
    "text": "4 Get financial data from data.sec.gov api for a specific XBRL line item tag\n\n# Build up the request URL\ncik = get_cik_string(df_tickers, ticker)\ntag = 'Assets'\nurl = f\"https://data.sec.gov/api/xbrl/companyconcept/{cik}/us-gaap/{tag}.json\"\n\nprint(\"URL:\", url)\n\n# Run the API request   \nrequest_tag_data = requests.get(url, headers={'User-Agent': email_address})\n\n# Print the returned status code (200 is good, 404 is bad), and other content info.\nprint(\"Request status code:\", request_tag_data.status_code)\nprint(\"Content Type:\", request_tag_data.headers['Content-Type'])\nprint(\"Content Length:\", request_tag_data.headers['Content-Length'], 'bytes')\n\nURL: https://data.sec.gov/api/xbrl/companyconcept/CIK0000320193/us-gaap/Assets.json\n\n\nRequest status code: 200\nContent Type: application/json\nContent Length: 2052 bytes\n\n\n\ntag_data = request_tag_data.json()\n\n\npprint(tag_data, depth=2)\n\n{'cik': 320193,\n 'description': 'Sum of the carrying amounts as of the balance sheet date of '\n                'all assets that are recognized. Assets are probable future '\n                'economic benefits obtained or controlled by an entity as a '\n                'result of past transactions or events.',\n 'entityName': 'Apple Inc.',\n 'label': 'Assets',\n 'tag': 'Assets',\n 'taxonomy': 'us-gaap',\n 'units': {'USD': [...]}}\n\n\n\ndf_tag_data = pd.DataFrame.from_dict(tag_data['units']['USD'])\n\n\ndf_tag_data\n\n\n\n\n\n  \n    \n      \n      end\n      val\n      accn\n      fy\n      fp\n      form\n      filed\n      frame\n    \n  \n  \n    \n      0\n      2008-09-27\n      39572000000\n      0001193125-09-153165\n      2009\n      Q3\n      10-Q\n      2009-07-22\n      NaN\n    \n    \n      1\n      2008-09-27\n      39572000000\n      0001193125-09-214859\n      2009\n      FY\n      10-K\n      2009-10-27\n      NaN\n    \n    \n      2\n      2008-09-27\n      36171000000\n      0001193125-10-012091\n      2009\n      FY\n      10-K/A\n      2010-01-25\n      NaN\n    \n    \n      3\n      2008-09-27\n      36171000000\n      0001193125-10-238044\n      2010\n      FY\n      10-K\n      2010-10-27\n      CY2008Q3I\n    \n    \n      4\n      2009-06-27\n      48140000000\n      0001193125-09-153165\n      2009\n      Q3\n      10-Q\n      2009-07-22\n      CY2009Q2I\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      111\n      2021-09-25\n      351002000000\n      0000320193-22-000108\n      2022\n      FY\n      10-K\n      2022-10-28\n      CY2021Q3I\n    \n    \n      112\n      2021-12-25\n      381191000000\n      0000320193-22-000007\n      2022\n      Q1\n      10-Q\n      2022-01-28\n      CY2021Q4I\n    \n    \n      113\n      2022-03-26\n      350662000000\n      0000320193-22-000059\n      2022\n      Q2\n      10-Q\n      2022-04-29\n      CY2022Q1I\n    \n    \n      114\n      2022-06-25\n      336309000000\n      0000320193-22-000070\n      2022\n      Q3\n      10-Q\n      2022-07-29\n      CY2022Q2I\n    \n    \n      115\n      2022-09-24\n      352755000000\n      0000320193-22-000108\n      2022\n      FY\n      10-K\n      2022-10-28\n      CY2022Q3I\n    \n  \n\n116 rows × 8 columns\n\n\n\n\n# Filter rows to only those with current year (CY) labels\nstarts_with_cy = lambda x: bool(isinstance(re.search(r'^CY', x), re.Match))\nx_axis_name = 'End Date'\ny_axis_name = f'{tag} (USD in Billions)'\n\ndf_plot_data = (\n    df_tag_data\n    .query(\"form=='10-Q'\")\n    .assign(yr_mon      = lambda x: [f\"{y[0]}-{y[1]}\" for y in zip(x.fy, x.fp)] )\n    .assign(filter_flag = lambda x: [starts_with_cy(str(y)) for y in x.frame])\n    .query(\"filter_flag==True\")\n    .filter(['end', 'val'])\n    .assign(val = lambda x: x.val/1000000000)\n    .rename(columns={'end':x_axis_name, 'val':y_axis_name})\n    .sort_values(by=x_axis_name)\n)\n\ndf_plot_data.tail(10)\n\n\n\n\n\n  \n    \n      \n      End Date\n      Assets (USD in Billions)\n    \n  \n  \n    \n      90\n      2019-06-29\n      322.239\n    \n    \n      96\n      2019-12-28\n      340.618\n    \n    \n      97\n      2020-03-28\n      320.400\n    \n    \n      98\n      2020-06-27\n      317.344\n    \n    \n      104\n      2020-12-26\n      354.054\n    \n    \n      105\n      2021-03-27\n      337.158\n    \n    \n      106\n      2021-06-26\n      329.840\n    \n    \n      112\n      2021-12-25\n      381.191\n    \n    \n      113\n      2022-03-26\n      350.662\n    \n    \n      114\n      2022-06-25\n      336.309\n    \n  \n\n\n\n\n\ndf_plot_data.plot(kind = 'bar', x = x_axis_name, y = y_axis_name, figsize=(12, 5), title = f\"{ticker} {tag}\")\nplt.show()\n\n\n\n\n::::"
  },
  {
    "objectID": "posts/stock_ticker_data/stock_ticker_data.html#parameters",
    "href": "posts/stock_ticker_data/stock_ticker_data.html#parameters",
    "title": "Get Stock Ticker Data from the data.sec.gov API",
    "section": "2 Parameters",
    "text": "2 Parameters\n\nticker = 'AAPL'\nemail_address = 'your-email@example.com'  # Enter your email address here.  It needs to be included in the URL of the API call."
  }
]